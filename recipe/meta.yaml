{% set name = "airflow" %}
{% set version = "2.3.3" %}
{% set sha256 = "f32d27b9c9e5c3a87c5631011c321cb9f4e86b8f880209095fa36eb576bdc3a8" %}

package:
  name: {{ name|lower }}-split
  version: {{ version }}

source:
  fn: {{ name }}-{{ version }}.tar.gz
  url: https://github.com/apache/{{ name }}/archive/{{ version }}.tar.gz
  sha256: {{ sha256 }}

build:
  skip: true  # [win]
  number: 0

outputs:
  - name: {{ name }}
    script: install_airflow.sh
    build:
      entry_points:
        - airflow=airflow.__main__:main
    requirements:
      host:
        - python
        - pip
        # for md5sum, cksum, sha256sum
        - coreutils
        - docutils
        - gitpython
        - yarn
        # seems to be having trouble with openssl 3.
        # By including it as a dependency, we can explicitly check
        - openssl
      run:
        - python
        - alembic >=1.5.1,<2.0
        - argcomplete >=1.10
        - attrs >=20.0,<21.0
        - blinker
        - cached-property >=1.5  # [py<=37]
        - cattrs >=1.1,<2,!=1.7.*
        - colorlog >=4.0.2,<5.0
        - connexion >=2.10.0

        # connexion[swagger-ui] dependencies
        - swagger-ui-bundle >=0.0.2,<0.1
        # connexion[flask] dependencies
        - flask >=1.0.4,<3
        - itsdangerous >=0.24

        - cron-descriptor >=1.2.24
        - croniter >=0.3.17
        - cryptography >=0.9.3
        - deprecated >=1.2.13
        - dill >=0.2.2
        - flask >=2.0
        - flask-appbuilder 4.1.2
        - flask-caching >=1.5.0
        - flask-login >=0.5
        - flask-session >=0.4.0
        - flask-wtf >=0.15
        - python-graphviz >=0.12
        - gunicorn >=19.5.0
        - httpx
        - importlib_metadata >=1.7  # [py<39]
        - importlib_resources >=5.2  # [py<39]
        - itsdangerous >=2.0
        - jinja2 >=2.10.1
        - jsonschema >=3.2.0
        - lazy-object-proxy
        - linkify-it-py >=2.0.0
        - lockfile >=0.12.2
        - markdown>=3.0
        - markdown-it-py >=2.1.0
        - markupsafe >=1.1.1
        - marshmallow-oneofschema >=2.0.1
        - mdit-py-plugins >=0.3.0
        - packaging >=14.0
        - pathspec >=0.9.0,<1.0
        - pendulum >=2.0
        - pluggy>=1.0
        - psutil >=4.2.0
        - pygments >=2.0.1
        - pyjwt >=2.0.0
        - python-daemon >=2.2.4
        - python-dateutil >=2.3
        - python-nvd3 >=0.15.0
        - python-slugify >=5.0
        - rich >=12.4.4
        - setproctitle >=1.1.8
        - sqlalchemy >=1.4
        - sqlalchemy-jsonfield >=1.0
        - tabulate >=0.7.5
        - tenacity >=6.2.0
        - termcolor >=1.1.0
        - typing-extensions >=3.7.4
        - unicodecsv >=0.14.1
        - werkzeug >=2.0
        - apache-airflow-providers-ftp
        - apache-airflow-providers-http
        - apache-airflow-providers-imap
        - apache-airflow-providers-sqlite
        # seems to be having trouble with openssl 3.
        # By including it as a dependency, we can explicitly check
        - openssl

    test:
      commands:
        - pip check
        - airflow --help
        - airflow db init
      imports:
        - airflow
        - airflow.api
        - airflow.api.auth
        - airflow.api.auth.backend
        - airflow.api.client
        - airflow.api.common
        - airflow.api.common.experimental
        - airflow.api_connexion
        - airflow.cli
        - airflow.cli.commands
        - airflow.config_templates
        - airflow.contrib
        - airflow.contrib.hooks
        - airflow.contrib.operators
        - airflow.contrib.secrets
        - airflow.contrib.sensors
        - airflow.contrib.task_runner
        - airflow.contrib.utils
        - airflow.example_dags
        - airflow.example_dags.subdags
        - airflow.executors
        - airflow.hooks
        - airflow.jobs
        - airflow.kubernetes
        - airflow.lineage
        - airflow.macros
        - airflow.migrations
        - airflow.migrations.versions
        - airflow.models
        - airflow.mypy
        - airflow.mypy.plugin
        - airflow.operators
        - airflow.secrets
        - airflow.security
        - airflow.sensors
        - airflow.serialization
        - airflow.smart_sensor_dags
        - airflow.task
        - airflow.task.task_runner
        - airflow.ti_deps
        - airflow.ti_deps.deps
        - airflow.utils
        - airflow.utils.log
        - airflow.www
        - airflow.www.api
        - airflow.www.api.experimental
      requires:
        - pip

  # alternative name for the core package
  - name: apache-airflow
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
    test:
      imports:
        - airflow
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-apache-atlas
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - atlasclient >=0.1.2
    test:
      imports:
        - airflow.lineage
        - airflow.lineage.entities
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-apache-webhdfs
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - python-hdfs >=2.0.4
        - apache-airflow-providers-apache-hdfs
    test:
      imports:
        - airflow
        - hdfs
        - airflow.hooks.webhdfs_hook
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-async
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - eventlet >=0.9.7
        - gevent >=0.13
        - greenlet >=0.4.9
    test:
      imports:
        - airflow
        - eventlet
        - gevent
        - greenlet
      commands:
        - pip check
      requires:
        - pip

# this one isn't happy with openssl >=1.1.1n,<1.1.2a for some reason that
# I can't reproduce easily with a local test
#  - name: {{ name }}-with-celery
#    requirements:
#      host:
#        - python
#      run:
#        - python
#        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
#        - celery >=5.2.3,<6
#        - flower >=1.0.0
#    test:
#      imports:
#        - airflow
#        - celery
#      commands:
#        - pip check
#      requires:
#        - pip

  - name: {{ name }}-with-cgroups
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cgroupspy >=0.2.2
    test:
      imports:
        - airflow
        - cgroupspy
        - airflow.contrib.task_runner.cgroup_task_runner
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-cncf-kubernetes
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cryptography >=2.0.0
        - python-kubernetes >=21.7.0,<24
    test:
      imports:
        - airflow
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-dask
    build:
      # distributed<2.20 was not built for py39
      skip: true  # [py>=39]
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cloudpickle >=1.4.1
        - dask >=2.9.0
        - distributed >=2.11.1
    test:
      imports:
        - airflow
        - distributed
        - airflow.executors.dask_executor
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-deprecated-api
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - requests >=2.26.0
    test:
      imports:
        - airflow
      commands:
        - pip check
      requires:
        - pip


  - name: {{ name }}-with-github_enterprise
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - flask-appbuilder
        # flask-appbuilder[oauth]
        - authlib >=0.14,<1.0.0
    test:
      imports:
        - airflow
        - authlib
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-google_auth
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - flask-appbuilder
        # flask-appbuilder[oauth]
        - authlib >=0.14,<1.0.0
    test:
      imports:
        - airflow
        - authlib
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-kerberos
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pykerberos >=1.1.13
        - requests-kerberos >=0.10.0
        - thrift_sasl >=0.2.0
        # temporary dependencies because of bad build of thrift_sasl
        - thrift >=0.13
        - pure-sasl >=0.6.2
        - six >=1.13.0
    test:
      imports:
        - airflow
        - kerberos
        - airflow.api.auth.backend.kerberos_auth
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-ldap
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - ldap3 >=2.5.1
        - python-ldap
    test:
      imports:
        - airflow
        - ldap3
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-leveldb
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - plyvel
    test:
      imports:
        - airflow
        - plyvel
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-pandas
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pandas >=0.17.1
    test:
      imports:
        - airflow
        - pandas
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-password
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - bcrypt >=2.0.0
        - flask-bcrypt >=0.7.1
    test:
      imports:
        - airflow
        - flask_bcrypt
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-rabbitmq
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - amqp
    test:
      imports:
        - airflow
        - amqp
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-sentry
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - blinker >=1.1
        - sentry-sdk >=0.8.0
    test:
      imports:
        - airflow
        - sentry_sdk
        - airflow.sentry
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-statsd
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - statsd >=3.3.0
    test:
      imports:
        - airflow
        - statsd
      commands:
        - pip check
      requires:
        - pip

  - name: {{ name }}-with-virtualenv
    requirements:
      host:
        - python
      run:
        - python
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - virtualenv
    test:
      imports:
        - airflow
        - virtualenv
      commands:
        - pip check
      requires:
        - pip

about:
  home: http://airflow.apache.org
  license: Apache-2.0
  license_file: LICENSE
  summary: |
    Airflow is a platform to programmatically author, schedule and monitor
    workflows

  description: |
    Use airflow to author workflows as directed acyclic graphs (DAGs)
    of tasks. The airflow scheduler executes your tasks on an array of
    workers while following the specified dependencies. Rich command
    line utilities make performing complex surgeries on DAGs a snap.
    The rich user interface makes it easy to visualize pipelines
    running in production, monitor progress, and troubleshoot issues
    when needed.

    When workflows are defined as code, they become more maintainable,
    versionable, testable, and collaborative.

  doc_url: http://pythonhosted.org/airflow/profiling.html
  dev_url: https://github.com/apache/airflow

extra:
  recipe-maintainers:
    - sodre
    - halldc
    - xylar
