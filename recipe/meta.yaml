{% set name = "airflow" %}
{% set version = "1.10.13" %}
{% set sha256 = "fecde45943b7a99dba30acd902f1311bc238bb8d975c98102a453c6f795ba48c" %}

package:
  name: {{ name|lower }}-split
  version: {{ version }}

source:
  fn: {{ name }}-{{ version }}.tar.gz
  url: https://github.com/apache/incubator-{{ name }}/archive/{{ version }}.tar.gz
  sha256: {{ sha256 }}

build:
  skip: true  # [win or py<35]
  number: 0

test:
  commands:
    - echo 'Keep lint happy'

outputs:
  - name: {{ name }}
    script: install_airflow.sh  # [unix]
    requirements:
      host:
        - python
        - pip
        - gitpython >=2.0.2
        - docutils >=0.14,<1.0
        - yarn
      run:
        - python
        - alembic >=1.0,<2.0
        - argcomplete >=1.10.0,<1.11.0
        - attrs >=19.3,<19.4
        - cached-property >=1.5.0,<1.6.0
        - cattrs >=1.0,<1.1.0
        - colorlog 4.0.2
        - configparser >=3.5.0,<3.6.0
        - croniter >=0.3.17,<0.4
        - dill >=0.2.2,<0.4
        - email-validator
        - enum34 >=1.1.6,<1.2.0  # [py<34]
        - flask >=1.1.0,<2.0
        - flask-admin 1.5.4
        - flask-appbuilder >=1.12.2,<2.0.0  # [py<36]
        - flask-appbuilder >=2.2,<2.3  # [py>=36]
        - flask-caching >=1.3.3,<1.4.0
        - flask-login >=0.3,<0.5
        - flask-swagger 0.2.13,<0.3
        - flask-wtf >=0.14.2,<0.15
        - funcsigs >=1.0.0,<2.0.0
        - future >=0.16.0,<0.19
        - python-graphviz >=0.12
        - gunicorn >=19.5.0,<21.0
        - iso8601 >=0.1.12
        - jinja2 >=2.10.1,<2.12.0
        - json-merge-patch 0.2
        - jsonschema >=3.0.0,<3.1.0  # [py<38]
        # Earlier versions were not build with py38, so this is newer than upstream spec
        - jsonschema >=3.1.0,<3.2.0  # [py>=38]
        - lazy-object-proxy >=1.3.0,<1.4.0
        - markdown >=2.5.2,<3.0
        - marshmallow-sqlalchemy >=0.16.1,<0.19.0  # [py<36]
        - pandas >=0.17.1,<2.0.0
        - pendulum 1.4.4
        - psutil >=4.2.0,<6.0.0
        - pygments >=2.0.1,<3.0
        - python-daemon >=2.1.1
        - python-dateutil >=2.3,<3
        - python-nvd3 >=0.15.0,<0.16.0
        - python-slugify >=3.0.0,<5.0
        - requests >=2.20.0,<3
        - setproctitle >=1.1.8,<2
        - sqlalchemy >=1.3.0,<1.4.0
        - sqlalchemy-jsonfield 0.8.0  # [py<35]
        - sqlalchemy-jsonfield >=0.9.0,<0.10.0  # [py>=35]
        - tabulate >=0.7.5,<0.9
        - tenacity 4.12.0
        - thrift >=0.9.2
        - typing  # [py<35]
        # contrary to upstream spec, this seems to be needed for py=38 as well
        - typing_extensions >=3.7.4
        - tzlocal >=1.4,<2.0.0
        - unicodecsv >=0.14.1
        - werkzeug<1.0.0
        - zope.deprecation >=4.0,<5.0
    test:
      commands:
        - airflow initdb
        - test -f $STDLIB_DIR/site-packages/airflow/www_rbac/static/dist/manifest.json
      imports:
        - airflow
        - airflow.api
        - airflow.api.auth
        - airflow.api.auth.backend
        - airflow.api.client
        - airflow.api.common
        - airflow.api.common.experimental
        - airflow.bin
        - airflow.config_templates
        - airflow.contrib
        - airflow.contrib.auth
        - airflow.contrib.auth.backends
        - airflow.contrib.hooks
        - airflow.contrib.kubernetes
        - airflow.contrib.operators
        - airflow.contrib.sensors
        - airflow.contrib.task_runner
        - airflow.contrib.utils
        - airflow.dag
        - airflow.example_dags
        - airflow.example_dags.subdags
        - airflow.executors
        - airflow.hooks
        - airflow.lineage
        - airflow.lineage.backend
        - airflow.macros
        - airflow.migrations
        - airflow.migrations.versions
        - airflow.operators
        - airflow.security
        - airflow.sensors
        - airflow.task
        - airflow.task.task_runner
        - airflow.ti_deps
        - airflow.ti_deps.deps
        - airflow.utils
        - airflow.utils.log
        - airflow.www
        - airflow.www.api
        - airflow.www.api.experimental
        - airflow.www_rbac
        - airflow.www_rbac.api
        - airflow.www_rbac.api.experimental


  - name: {{ name }}-with-async
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - eventlet >=0.9.7
        - gevent >=0.13
        - greenlet >=0.4.9
    test:
      imports:
        - airflow
        - eventlet
        - gevent
        - greenlet

  - name: {{ name }}-with-atlas
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - atlasclient >=0.1.2
    test:
      imports:
        - airflow.lineage.backend.atlas

  - name: {{ name }}-with-aws
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        # leaving this as is because it was just added, but noting that upstream
        # constraint is boto3~=1.10 and no watchtower
        - boto3 >=1.12.0,<2.0.0
        - watchtower 0.7.3
    test:
      imports:
        - airflow
        - boto3
        - watchtower
        - airflow.contrib.hooks.aws_hook

  - name: {{ name }}-with-azure_blob_storage
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - azure-storage >=0.34.0,<0.37.0
        - azure-storage-blob <12.0
    test:
      imports:
        - airflow
        - azure
        - azure.storage
        - azure.storage.blob
        - airflow.contrib.hooks.wasb_hook

  - name: {{ name }}-with-azure_data_lake
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - azure-datalake-store >=0.0.45
        - azure-mgmt-datalake-store >=0.5.0
        - azure-mgmt-resource >=2.2.0
    test:
      imports:
        - airflow
        - azure.datalake.store
        - airflow.contrib.hooks.azure_data_lake_hook

  - name: {{ name }}-with-azure_cosmos
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - azure-cosmos >=3.0.1,<4
    test:
      imports:
        - airflow
        - azure.cosmos
        - airflow.contrib.hooks.azure_cosmos_hook

  # Note: no azure-mgmt-containerinstance feedstock
  #- name: {{ name }}-with-azure-mgmt-containerinstance
  #  build:
  #    skip: true  # [py!=38]
  #  requirements:
  #    run:
  #      - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #      - azure-mgmt-containerinstance >=1.5.0,<2
  #  test:
  #    imports:
  #      - airflow
  #      - azure.mgmt.containerinstance

  - name: {{ name }}-with-cassandra
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cassandra-driver >=3.13.0,<3.21.0
    test:
      imports:
        - airflow
        - cassandra
        - airflow.contrib.hooks.cassandra_hook

  - name: {{ name }}-with-celery
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - celery >=4.3.0,<4.4.0
        - vine >=1.3.0,<5.0.0
        - flower >=0.7.3,<1.0
        - tornado >=4.2.0,<6.0
        - kombu 4.6.3  # [py<30]
    test:
      imports:
        - airflow
        - celery
        - airflow.executors.celery_executor

  - name: {{ name }}-with-cgroups
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cgroupspy >=0.1.4
    test:
      imports:
        - airflow
        - cgroupspy
        - airflow.contrib.task_runner.cgroup_task_runner

  - name: {{ name }}-with-cloudant
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        # leaving as is because older versions are not build with py>27 but
        # upstream constraint is cloudant>=0.5.9,<2.0
        - cloudant >=2.0
    test:
      imports:
        - airflow
        - cloudant
        - airflow.contrib.hooks.cloudant_hook

  - name: {{ name }}-with-crypto
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cryptography >=0.9.3
    test:
      imports:
        - airflow
        - cryptography
        - airflow.models.crypto

  # note: the older version of distributed pinned here is not available for
  # py38
  #- name: {{ name }}-with-dask
  #  build:
  #    skip: true  # [py!=38]
  #  requirements:
  #    run:
  #      - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #      - distributed >=1.17.1,<2
  #  test:
  #    imports:
  #      - airflow
  #      - distributed
  #      - airflow.executors.dask_executor

  - name: {{ name }}-with-databricks
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - requests >=2.20.0,<3
    test:
      imports:
        - airflow
        - requests
        - airflow.contrib.hooks.databricks_hook

  - name: {{ name }}-with-datadog
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - datadog >=0.14.0
    test:
      imports:
        - airflow
        - datadog
        - airflow.contrib.hooks.datadog_hook

  # note: the older version of docker-py pinned here is not available for
  # py38
  #- name: {{ name }}-with-docker
  #  build:
  #    skip: true  # [py!=38]
  #  requirements:
  #    run:
  #      - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #      - docker-py >=3.0.0,<3.1.0
  #  test:
  #    imports:
  #      - airflow
  #      - docker
  #      - airflow.hooks.docker_hook
  #      - airflow.operators.docker_operator

  - name: {{ name }}-with-druid
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pydruid >=0.4.1,<=0.5.8
    test:
      imports:
        - airflow
        - pydruid
        - airflow.hooks.druid_hook

  # note: the older version of elasticsearch-dsl pinned here is not available
  # for py38
  #- name: {{ name }}-with-elasticsearch
  #  build:
  #    skip: true  # [py!=38]
  #  requirements:
  #    run:
  #      - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #      - elasticsearch >=5.0.0,<6.0.0
  #      - elasticsearch-dsl >=5.0.0,<6.0.0
  #  test:
  #    imports:
  #      - airflow
  #      - elasticsearch

  # same as aws, but I'm taking upstream literally this time and leaving out
  # watchtower
  - name: {{ name }}-with-emr
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - boto3 >=1.10.0,<1.11.0
    test:
      imports:
        - airflow
        - boto3
        - airflow.contrib.hooks.aws_hook

  - name: {{ name }}-with-flask_oauth
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - flask-oauthlib >=0.9.1
        - oauthlib !=2.0.3,!=2.0.4,!=2.0.5,<3.0.0,>=1.1.2
        - requests-oauthlib 1.1.0
    test:
      imports:
        - airflow
        - flask_oauthlib

 # google-cloud-spanner is too out of date
 # google-cloud-secret-manager does not have a feedstock
 # google-cloud-speech does not have a feedstock
 # - name: {{ name }}-with-gcp
 #   build:
 #     skip: true  # [py!=38]
 #   requirements:
 #     run:
 #       - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
 #       - pyopenssl
 #       - google-api-python-client >=1.6.0,<2.0.0
 #       - google-auth >=1.0.0,<2.0.0
 #       - google-auth-httplib2 >=0.0.1
 #       - google-cloud-bigtable >=1.0.0,<2.0.0
 #       - google-cloud-container >=0.1.1,<2.0.0
 #       - google-cloud-dlp >=0.11.0,<2.0.0
 #       - google-cloud-language >=1.1.1,<2.0.0
 #       - google-cloud-secret-manager >=0.2.0,<2.0.0
 #       - google-cloud-spanner >=1.10.0,<2.0.0
 #       - google-cloud-speech >=0.36.3,<2.0.0
 #       - google-cloud-storage >=1.16,<2.0.0
 #       - google-cloud-texttospeech >=0.4.0,<2
 #       - google-cloud-translate >=1.3.3,<2.0.0
 #       - google-cloud-videointelligence >=1.7.0,<2.0.0
 #       - google-cloud-vision >=0.35.2,<2.0.0
 #       - grpcio-gcp >=0.2.2
 #       - pandas-gbq

  - name: {{ name }}-with-grpc
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - google-auth >=1.0.0,<2.0.0dev
        - grpcio >=1.15.0
    test:
      imports:
        - airflow
        - grpc
        - airflow.contrib.hooks.grpc_hook

  - name: {{ name }}-with-hashicorp
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - hvac >=0.10.0,<0.11.0
    test:
      imports:
        - airflow
        - hvac
        - airflow.contrib.secrets.hashicorp_vault

  # this is unlikely to remain useful since snakebite only supports py<=27
  # and hasn't been updated in 4 years
  #- name: {{ name }}-with-hdfs
  #  build:
  #    skip: true  # [py!=38]
  #  requirements:
  #    run:
  #      - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #      - snakebite >=2.7.8
  #  test:
  #    imports:
  #      - airflow
  #      - airflow.hooks.hdfs_hook

  - name: {{ name }}-with-hive
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - hmsclient >=0.1.0
        - pyhive >=0.6.0
    test:
      imports:
        - airflow
        - pyhive
        - airflow.hooks.hive_hooks

  # note: upstream pin jpype1==0.7.1 was not built on conda-forge
  #- name: {{ name }}-with-jdbc
  #  build:
  #    skip: true  # [py!=38]
  #  requirements:
  #    run:
  #      - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #      - jpype1 0.7.1
  #      - jaydebeapi >=1.1.1
  #  test:
  #    imports:
  #      - airflow
  #      - airflow.hooks.jdbc_hook

  - name: {{ name }}-with-jenkins
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - python-jenkins >=1.0.0
    test:
      imports:
        - airflow
        - jenkins
        - airflow.contrib.hooks.jenkins_hook

  - name: {{ name }}-with-jira
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - jira >=1.0.7
    test:
      imports:
        - airflow
        - jira
        - airflow.contrib.hooks.jira_hook

  # this is unlikely to be useful since snakebite only supports py<=27
  # and hasn't been updated in 4 years
  #- name: {{ name }}-with-kerberos
  #  build:
  #    skip: true  # [py!=38]
  #  requirements:
  #    run:
  #      - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #      - pykerberos >=1.1.13
  #      - requests-kerberos >=0.10.0
  #      - snakebite[kerberos] >=2.7.8
  #      - thrift_sasl >=0.2.0
  #  test:
  #    imports:
  #      - airflow
  #      - kerberos
  #      - airflow.api.auth.backend.kerberos_auth

  - name: {{ name }}-with-kubernetes
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - python-kubernetes >=3.0.0
        - cryptography >=2.0.0
    test:
      imports:
        - airflow
        - kubernetes
        - airflow.executors.kubernetes_executor

  - name: {{ name }}-with-ldap
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - ldap3 >=2.5.1
    test:
      imports:
        - airflow
        - ldap3
        - airflow.contrib.auth.backends.ldap_auth

  - name: {{ name }}-with-mongo
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pymongo >=3.6.0,<3.11.0
        - dnspython >=1.13.0,<2.0.0
    test:
      imports:
        - airflow
        - pymongo
        - airflow.contrib.hooks.mongo_hook

  # note: the version of pymssql pinned here is not available for py38 and
  # newer builds are not getting merged
  #- name: {{ name }}-with-mssql
  #  build:
  #    skip: true  # [py!=38]
  #  requirements:
  #    run:
  #      - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #      - pymssql >=2.1.1,<2.2.0
  #  test:
  #    imports:
  #      - airflow
  #      - pymssql
  #      - airflow.hooks.mssql_hook

  # note: the older version of mysqlclient pinned here is not available for py38
  #- name: {{ name }}-with-mysql
  #  build:
  #    skip: true  # [py!=38]
  #  requirements:
  #    run:
  #      - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #      - mysqlclient >=1.3.6,<1.4
  #  test:
  #    imports:
  #      - airflow
  #      - MySQLdb
  #      - airflow.hooks.mysql_hook

  - name: {{ name }}-with-oracle
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - cx_oracle >=5.1.2,<8.0.0  # [py<30]
        - cx_oracle >=5.1.2  # [py>=30]
    test:
      imports:
        - airflow
        - cx_Oracle
        - airflow.hooks.oracle_hook

  - name: {{ name }}-with-pagerduty
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pypd >=1.1.0
    test:
      imports:
        - airflow
        - pypd

  - name: {{ name }}-with-papermill
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - papermill[all] >=1.0.0
        - nteract-scrapbook[all] >=0.2.1
        - pyarrow <1.0.0
        - fsspec <0.8.0  # [py35]
    test:
      imports:
        - airflow
        - papermill
        - airflow.operators.papermill_operator

  - name: {{ name }}-with-password
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - bcrypt >=2.0.0
        - flask-bcrypt >=0.7.1
    test:
      imports:
        - airflow
        - flask_bcrypt
        - airflow.contrib.auth.backends.password_auth

  # no pinotdb feedstock
  # - name: {{ name }}-with-pinot
  #  build:
  #    skip: true  # [py!=38]
  #   requirements:
  #     run:
  #       - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #       - pinotdb 0.1.1
  #  test:
  #    imports:
  #      - airflow
  #      - pinotdb
  #      - airflow.contrib.hooks.pinot_hook

  - name: {{ name }}-with-postgres
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - psycopg2 >=2.7.4
    test:
      imports:
        - airflow
        - psycopg2
        - airflow.hooks.postgres_hook

  # not presto-python-client feedstock
  # - name: {{ name }}-with-presto
  #  build:
  #    skip: true  # [py!=38]
  #   requirements:
  #     run:
  #       - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #       - presto-python-client >=0.7.0,<0.8
  #  test:
  #    imports:
  #      - airflow
  #      - prestodb
  #      - airflow.hooks.presto_hook

  - name: {{ name }}-with-qds
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - qds-sdk >=1.10.4
    test:
      imports:
        - airflow
        - qds_sdk
        - airflow.contrib.hooks.qubole_hook

  - name: {{ name }}-with-rabbitmq
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - amqp
    test:
      imports:
        - airflow
        - amqp

  - name: {{ name }}-with-redis
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - redis-py >=3.2.0,<3.3.0
    test:
      imports:
        - airflow
        - redis
        - airflow.contrib.hooks.redis_hook

  - name: {{ name }}-with-salesforce
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - simple-salesforce >=0.72,<1.0.0
    test:
      imports:
        - airflow
        - simple_salesforce
        - airflow.contrib.hooks.salesforce_hook

  - name: {{ name }}-with-samba
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pysmbclient >=0.1.3
    test:
      imports:
        - airflow
        - smbclient
        - airflow.hooks.samba_hook

  - name: {{ name }}-with-segment
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - analytics-python >=1.2.9
    test:
      imports:
        - airflow
        - analytics
        - airflow.contrib.hooks.segment_hook

  - name: {{ name }}-with-sendgrid
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - sendgrid >=5.2.0,<6
    test:
      imports:
        - airflow
        - sendgrid
        - airflow.contrib.utils.sendgrid

  - name: {{ name }}-with-sentry
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - blinker >=1.1
        - sentry-sdk >=0.8.0
    test:
      imports:
        - airflow
        - sentry_sdk
        - airflow.sentry

  - name: {{ name }}-with-slack
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - slackclient >=1.0.0,<2.0.0
    test:
      imports:
        - airflow
        - slackclient
        - airflow.hooks.slack_hook

  - name: {{ name }}-with-snowflake
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - snowflake-connector-python >=1.5.2
        - snowflake-sqlalchemy >=1.1.0
    test:
      imports:
        - airflow
        - snowflake
        - airflow.contrib.hooks.snowflake_hook

  - name: {{ name }}-with-ssh
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - paramiko >=2.1.1
        - pysftp >=0.2.9
        - sshtunnel >=0.1.4,<0.2
    test:
      imports:
        - airflow
        - sshtunnel
        - pysftp
        - airflow.contrib.hooks.ssh_hook

  - name: {{ name }}-with-statsd
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - statsd >=3.3.0,<4.0
    test:
      imports:
        - airflow
        - statsd

  - name: {{ name }}-with-vertica
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - vertica-python >=0.5.1
    test:
      imports:
        - airflow
        - vertica_python
        - airflow.contrib.hooks.vertica_hook

  - name: {{ name }}-with-virtualenv
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - virtualenv
    test:
      imports:
        - airflow
        - virtualenv

  - name: {{ name }}-with-webhdfs
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - python-hdfs >=2.0.4
    test:
      imports:
        - airflow
        - hdfs
        - airflow.hooks.webhdfs_hook

  - name: {{ name }}-with-winrm
    build:
      skip: true  # [py!=38]
    requirements:
      run:
        - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
        - pywinrm >=0.4.0,<0.5.0
    test:
      imports:
        - airflow
        - winrm
        - airflow.contrib.hooks.winrm_hook

  # no zdest feedstock
  # - name: {{ name }}-with-zendesk
  #  build:
  #    skip: true  # [py!=38]
  #   requirements:
  #     run:
  #       - {{ pin_subpackage(name, max_pin='x.x.x.x.x.x') }}
  #       - zdesk
  #  test:
  #    imports:
  #      - airflow
  #      - zdesk
  #      - airflow.hooks.zendesk_hook

about:
  home: http://airflow.apache.org
  license: Apache-2.0
  license_file: LICENSE
  summary: |
    Airflow is a platform to programmatically author, schedule and monitor
    workflows

  description: |
    Use airflow to author workflows as directed acyclic graphs (DAGs)
    of tasks. The airflow scheduler executes your tasks on an array of
    workers while following the specified dependencies. Rich command
    line utilities make performing complex surgeries on DAGs a snap.
    The rich user interface makes it easy to visualize pipelines
    running in production, monitor progress, and troubleshoot issues
    when needed.

    When workflows are defined as code, they become more maintainable,
    versionable, testable, and collaborative.

  doc_url: http://pythonhosted.org/airflow/profiling.html
  dev_url: https://github.com/apache/airflow

extra:
  recipe-maintainers:
    - sodre
    - halldc
    - xylar
